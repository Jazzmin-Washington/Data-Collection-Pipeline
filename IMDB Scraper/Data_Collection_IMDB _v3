#%%
# IMBD Practical
import selenium
from selenium.webdriver import Chrome
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException
from selenium.common.exceptions import NoSuchElementException
from bs4 import BeautifulSoup
import time


class Scraper():
    def __init__(self):
        self.driver = Chrome('./chromedriver')
        url = 'https://www.imdb.com/title/tt0110912/?ref_=nv_sr_srsg_0'
        # Scraper Class to Navigate Website
        self.driver.get(url)
        self.actor_actress = []
        self.link_list = []
        self.delay = 10
        self.actor_link_movie = {'actor':[], 'link':[], 'movies':[{'title':[], 'year':[]}]}

    
    def get_links(self):
        self.actor_container = WebDriverWait(self.driver, self.delay).until(EC.presence_of_element_located((By.XPATH,'//div[@class="ipc-sub-grid ipc-sub-grid--page-span-2 ipc-sub-grid--wraps-at-above-l ipc-shoveler__grid"]')))
        self.actor_list = self.actor_container.find_elements_by_xpath('./div')
        time.sleep(10)
        for casting in self.actor_list:
            a_tag = casting.find_element_by_tag_name('a')
            link = a_tag.get_attribute('href')
            self.link_list.append(link)
            self.actor_link_movie['link'].append(link)
        print(self.actor_link_movie)

    def get_author(self):
        self.actor_container2 = WebDriverWait(self.driver, self.delay).until(EC.presence_of_element_located((By.XPATH,'//div[@class="ipc-sub-grid ipc-sub-grid--page-span-2 ipc-sub-grid--wraps-at-above-l ipc-shoveler__grid"]')))
        self.actor_listing = self.actor_container.find_elements_by_xpath('./div')
        time.sleep(10)
        for casting in self.actor_listing:
            b_tag = casting.find_element_by_tag_name('a')
            author = b_tag.get_attribute('aria-label')
            self.actor_actress.append(author)
            self.actor_link_movie['actor'].append(author)
        print(self.actor_link_movie)
            

    def get_data(self):
        link_num = len(self.link_list)
        print(link_num)
        for i in range(link_num):
            self.driver.get(self.link_list[i])
            time.sleep(15)
            self.film_container = WebDriverWait(self.driver, self.delay).until(EC.presence_of_element_located((By.XPATH,'//div[@class="filmo-category-section"]')))
            self.film_list = self.film_container.find_elements_by_xpath('./div')
            for actor_in_film in self.film_list:
                time.sleep(10)
                try:
                    self.year = actor_in_film.find_element_by_xpath('./span[@class = "year_column"]').text
                    self.actor_link_movie['movies']['year'].append(self.year)
                except NoSuchElementException:
                    self.actor_link_movie['movies']['year'].append('None')
                print(self.actor_link_movie)    
                try:
                    self.title = actor_in_film.find_element_by_xpath('./b').text
                    self.actor_link_movie['movies']['title'].append(self.title)
                except NoSuchElementException:
                    self.actor_link_movie['movies']['title'].append('None')
                print(self.actor_link_movie)    
                
                time.sleep(10)
            print(self.actor_link_movie[i])

# Run the programs and functions
    def scrape_website(self):
        self.get_links()
        self.get_author()
        self.get_data()
        self.driver.quit()

new_Scraper_Website = Scraper()
new_Scraper_Website.scrape_website()