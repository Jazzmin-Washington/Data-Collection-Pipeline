#%%
# IMBD Practical
import selenium
from selenium.webdriver import Chrome
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
from selenium.common.exceptions import TimeoutException
from selenium.common.exceptions import NoSuchElementException
from bs4 import BeautifulSoup
import time


class Scraper():
    def __init__(self):
        self.driver = Chrome('./chromedriver')
        url = 'https://www.imdb.com/title/tt0110912/?ref_=nv_sr_srsg_0'
        # Scraper Class to Navigate Website
        self.driver.get(url)
        self.actor_list = []
        self.actor_links = []
        self.delay = 10

    
    def get_actor_links(self):
        self.actor_container = WebDriverWait(self.driver, self.delay).until(EC.presence_of_element_located((By.XPATH,'//div[@class="ipc-sub-grid ipc-sub-grid--page-span-2 ipc-sub-grid--wraps-at-above-l ipc-shoveler__grid"]')))
        self.actor_list = self.actor_container.find_elements_by_xpath('./div')
        time.sleep(10)
        for casting in self.actor_list:
            a_tag = self.driver.find_element_by_xpath('/html/body/div[2]/main/div/section[1]/div/section/div/div[1]/section[4]/div[2]/div[2]/div[2]/div[1]/div/a')
            actor_link = a_tag.get_attribute('href')
            actor_name = a_tag.get_attribute('aria-label')
            self.actor_links.append(actor_link)
            self.actor_list.append(actor_name)
            self.actor_link_movie = {'actor':[], 'link':[], 'movies':[{'title':[], 'year':[]}]}
            self.actor_link_movie['actor'].append(actor_name)
            self.actor_link_movie['actor'].append(actor_link)
        print(self.actor_links)
        print(self.actor_list)
            
    
    def get_data(self):
        link_num = len(self.link_list)
        print(link_num)
        for i in range(link_num):
            self.driver.get(self.link_list[i])
            time.sleep(15)
            self.film_container = self.driver.find_elements_by_class_name('//div[@class="filmo-category-section"]')
            self.film_list = self.film_container.find_elements_by_xpath('./div')
            for film in self.film_list:
                time.sleep(10)
                try:
                    span_tag = film.find_element_by_tag_name('span')
                    self.title = span_tag.get_attribute('class').text
                    self.actor_link_movie['movies']['year'].append(self.year)
                except NoSuchElementException:
                    self.actor_link_movie['movies']['year'].append('None')
                try:
                    a_tag = film.find_element_by_tag_name('b')
                    self.year = a_tag.get_attribute('href').text
                    self.actor_link_movie['movies']['title'].append(self.title)
                except NoSuchElementException:
                    self.actor_link_movie['movies']['year'].append('None')
                
                time.sleep(10)
                print(self.actor_link_movie[i])

                
            print(self.actor_link_movie)

# Run the programs and functions
    def scrape_website(self):
        self.get_actor_links()
        self.get_data()
        self.driver.quit()

new_Scraper_Website = Scraper()
new_Scraper_Website.scrape_website()


# %%
